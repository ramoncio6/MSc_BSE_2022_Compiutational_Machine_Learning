{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><ins>Extended Proejct:</ins></center>\n",
    "# <center><ins> Decision Trees, Random Forest, Ensemble Models & Neural Networks </ins></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>Part 1: Set-Up</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we import all the random packages and set a random seed to ensure the code is reproducible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'MachAr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d554c8957ff6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcategory_encoders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTargetEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcategory_encoders\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdateutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/category_encoders/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcategory_encoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjames_stein\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJamesSteinEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcategory_encoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat_boost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcategory_encoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglmm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGLMMEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcategory_encoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile_encoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuantileEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSummaryEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/category_encoders/glmm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcategory_encoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mordinal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrdinalEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcategory_encoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msmf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbayes_mixed_glm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBinomialBayesMixedGLM\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbgmm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/statsmodels/formula/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlm_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscrete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscrete_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdm_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_linear_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmlm_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneralized_linear_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mglm_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobust_linear_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mroblm_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/statsmodels/regression/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0myule_walker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_testing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPytestTester\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'yule_walker'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m from statsmodels.tools.decorators import (cache_readonly,\n\u001b[1;32m     45\u001b[0m                                           cache_writable)\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapper\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memplike\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melregress\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_ELRegOpts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                           cached_value, cached_data)\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapper\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumdiff\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapprox_fprime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msm_exceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mValueWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mHessianInversionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/statsmodels/tools/numdiff.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# NOTE: we only do double precision internally so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mEPS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMachAr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m _hessian_docs = \"\"\"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0m\u001b[1;32m    285\u001b[0m                              \"{!r}\".format(__name__, attr))\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'MachAr'"
     ]
    }
   ],
   "source": [
    "# Import all necessary packages\n",
    "import os,sys,inspect\n",
    "from tkinter import Image\n",
    "\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from math import floor, ceil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import mean, std\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from dfmapper import DataFrameMapper\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from category_encoders import TargetEncoder\n",
    "import category_encoders as ce\n",
    "import dateutil.parser\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import plot_tree\n",
    "from IPython.display import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import set_config\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from category_encoders import TargetEncoder\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import keras\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(3123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next task is to load our data. This includes: the 'mimic_train.csv' file with the train set -covariates and target variable included; the 'mimic_test_death.csv' file that provides the test set covariates; finally, we load the file 'mimic_diagnoses.csv' that includes the metadata. After the load, we represent the imported data in data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data and represent csv as dataframe\n",
    "data = pd.read_csv(\"/Users/Ramon/Documents/Estudio/BSE/Term_1/Computational_Machine_Learning/Tests/Test_2/mimic_train.csv\")\n",
    "data = pd.DataFrame(data)\n",
    "data.nunique()\n",
    "\n",
    "X_test0 = pd.read_csv(\"//Users/Ramon/Documents/Estudio/BSE/Term_1/Computational_Machine_Learning/Tests/Test_2/mimic_test_death.csv\")\n",
    "X_test0 = pd.DataFrame(X_test0)\n",
    "\n",
    "X_metadata = pd.read_csv(\"//Users/Ramon/Documents/Estudio/BSE/Term_1/Computational_Machine_Learning/Tests/Test_2/MIMIC_diagnoses.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief exploration of our datasets is performed to gain a preliminary intuition of our variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20885, 41)\n",
      "(5221, 39)\n",
      "Index(['HOSPITAL_EXPIRE_FLAG', 'subject_id', 'hadm_id', 'icustay_id',\n",
      "       'HeartRate_Min', 'HeartRate_Max', 'HeartRate_Mean', 'SysBP_Min',\n",
      "       'SysBP_Max', 'SysBP_Mean', 'DiasBP_Min', 'DiasBP_Max', 'DiasBP_Mean',\n",
      "       'MeanBP_Min', 'MeanBP_Max', 'MeanBP_Mean', 'RespRate_Min',\n",
      "       'RespRate_Max', 'RespRate_Mean', 'TempC_Min', 'TempC_Max', 'TempC_Mean',\n",
      "       'SpO2_Min', 'SpO2_Max', 'SpO2_Mean', 'Glucose_Min', 'Glucose_Max',\n",
      "       'Glucose_Mean', 'GENDER', 'DOB', 'ADMITTIME', 'Diff', 'ADMISSION_TYPE',\n",
      "       'INSURANCE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY', 'DIAGNOSIS',\n",
      "       'ICD9_diagnosis', 'FIRST_CAREUNIT', 'LOS'],\n",
      "      dtype='object')\n",
      "1.1244    6\n",
      "1.0845    6\n",
      "0.8418    6\n",
      "1.1540    5\n",
      "0.9278    5\n",
      "         ..\n",
      "1.7459    1\n",
      "5.2682    1\n",
      "1.0348    1\n",
      "1.3858    1\n",
      "5.8260    1\n",
      "Name: LOS, Length: 16891, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Exploring Data Sets\n",
    "print(data.shape)\n",
    "print(X_test0.shape)\n",
    "print(data.columns)\n",
    "print(data[\"LOS\"].value_counts())\n",
    "\n",
    "# Save incustay id to use as index \n",
    "icustay_id=X_test0[\"icustay_id\"]\n",
    "icustay_id = pd.DataFrame(icustay_id,columns=['icustay_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>Part 2: Pre-Processing</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Analyzing columns with lots of NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A preliminary treatment of missing values involves dropping those columns that have 15% or more missing values as the information cost associated to imputing them may outweight their explicative power. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check features that have a'lot of missing values\n",
    "data.isna().sum()\n",
    "\n",
    "# Percentage of null in every column\n",
    "null_percentage = data.isnull().sum()/data.shape[0]*100\n",
    "\n",
    "# Drop columns having more than 15% null\n",
    "col_to_drop = null_percentage[null_percentage>15].keys()\n",
    "data1 = data.drop(col_to_drop, axis=1)\n",
    "\n",
    "# Update test set with columns dropped in training set\n",
    "X_test1 = X_test0.drop(col_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As no columns have more that 15% of missing values, the X training set wasn't affected. Concomitantly, no variables were dropped in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) New features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Age Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the age of each patient is not explicitely present in the dataset, it may be infered. We have the admision time and the date of birth of almost every patient. Therefore, by performing a simple subtraction we can obtain the estimated age of most of the patients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAELCAYAAAD3HtBMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaAElEQVR4nO3de7RkZXnn8e9PVGRUJggNYjfYrWIiME5HOsjEy+AlgpIRMKPSYwQNa1pdaDRxEiHOEpJMz6AJatCItsoCEgUxyGUtMIKu4CXhYoPcEWnoVltaaNEoRkNC88wfex8sD3VOd+2uc6qK8/2sVevseve7q56zgfPwXvb7pqqQJGlQjxp1AJKkyWQCkSR1YgKRJHViApEkdWICkSR18uhRBzCfdtttt1q6dOmow5CkiXLNNdf8oKoWTS9fUAlk6dKlrF27dtRhSNJESfLtfuV2YUmSOjGBSJI6MYFIkjoxgUiSOjGBSJI6MYFIkjoxgUiSOjGBSJI6MYFIkjpZUE+iq7+lx1/80PGGkw8bYSSSJoktEElSJyYQSVInJhBJUicmEElSJyYQSVInJhBJUicmEElSJyYQSVInJhBJUicmEElSJ/OaQJKcnuSeJDf1lH0myXXta0OS69rypUl+3nPuoz3XHJDkxiTrkpyaJPP5e0iS5n8trDOADwNnTRVU1WunjpOcAvy4p/4dVbW8z+ecBqwCrgQuAQ4FPj/8cCVJM5nXFkhVfQX4Yb9zbSviNcDZs31Gkj2BnavqiqoqmmR0xJBDlSRtxTiNgbwAuLuqbu8pW5bkG0m+nOQFbdliYGNPnY1tmSRpHo3Tcu4r+eXWxyZg76q6N8kBwAVJ9gP6jXfUTB+aZBVNdxd77733EMOVpIVtLFogSR4NvAr4zFRZVd1fVfe2x9cAdwDPpGlxLOm5fAlw10yfXVVrqmpFVa1YtGjRXIQvSQvSWCQQ4KXAN6vqoa6pJIuS7NAePw3YB7izqjYB9yU5qB03ORq4cBRBS9JCNt/TeM8GrgB+NcnGJMe2p47i4YPnLwRuSHI98HfAm6tqagD+LcAngHU0LRNnYEnSPJvXMZCqWjlD+Rv6lJ0HnDdD/bXA/kMNTpI0kHHpwpIkTRgTiCSpExOIJKmTcXoORBNi6fEXP3S84eTDRhiJpFGyBSJJ6sQEIknqxAQiSerEBCJJ6sQEIknqxAQiSerEBCJJ6sQEIknqxAQiSerEBCJJ6sSlTDQjlyyRNBtbIJKkTkwgkqRO7MJaQOySkjRMtkAkSZ3MawJJcnqSe5Lc1FN2UpLvJbmufb2i59wJSdYluS3JIT3lByS5sT13apLM5+8hSZr/FsgZwKF9yj9QVcvb1yUASfYFjgL2a6/5SJId2vqnAauAfdpXv8+UJM2heU0gVfUV4IfbWP1w4Jyqur+q1gPrgAOT7AnsXFVXVFUBZwFHzEnAkqQZjcsYyFuT3NB2ce3Sli0GvttTZ2Nbtrg9nl7eV5JVSdYmWbt58+Zhxy1JC9Y4JJDTgKcDy4FNwClteb9xjZqlvK+qWlNVK6pqxaJFi7YzVEnSlJEnkKq6u6q2VNWDwMeBA9tTG4G9eqouAe5qy5f0KZckzaORJ5B2TGPKkcDUDK2LgKOS7JhkGc1g+dVVtQm4L8lB7eyro4EL5zVoSdL8PkiY5GzgYGC3JBuBE4GDkyyn6YbaALwJoKpuTnIucAvwAHBcVW1pP+otNDO6dgI+374kSfNoXhNIVa3sU/zJWeqvBlb3KV8L7D/E0CRJAxp5F5YkaTKZQCRJnZhAJEmduBqvhsbVfqWFxQSiX9KbBCRpNnZhSZI6MYFIkjqxC2uBsqtK0vayBSJJ6sQEIknqxAQiSerEBCJJ6sQEIknqZKAEkmR1kqfOVTCSpMkxaAvk94E7klyS5JVJbMFI0gI1aAJ4MnAcsAdwAfDtJCcmWTzswCRJ422gBFJV/1JVH6uqA4DnApcCfwSsT3J+kkPnIkhJ0vjp3AVVVV+vqmOBZcA/AYcDFye5M8lxdm9J0iNb5z/ySZ6e5H3AzcBvAucDrwOuAD4IfLTPNacnuSfJTT1lf5Hkm0luaFsxv9KWL03y8yTXta+P9lxzQJIbk6xLcmqSdP09JEndDDoLa4ck/z3JZcBtNAnjNGBpVf1OVZ1TVa8D3ga8ts9HnAFM7+a6DNi/qp4NfAs4oefcHVW1vH29uaf8NGAVsE/7sutMkubZoC2Q7wGfoVmEcSXw1Ko6sarumlbvG8ATp19cVV8Bfjit7NKqeqB9eyWwZLYAkuwJ7FxVV1RVAWcBRwz4e0iSttOgCeSzNK2FF1XVZ3v+8P+Sqrqqqrp0j/0e8Pme98uSfCPJl5O8oC1bDGzsqbOxLesryaoka5Os3bx5c4eQJEn9DLSce1W9ba4CSfJu4AHgU23RJmDvqro3yQHABUn2A/qNd9RMn1tVa4A1ACtWrJixniRpMAMlkCTvApb0SyRJTgW+W1V/MWgQSY4Bfht4SdstRVXdD9zfHl+T5A7gmTQtjt5uriXA9C40zRP3FZEWrkG7md4I3DDDueva8wNpnx15F/DKqvpZT/miJDu0x0+jGSy/s6o2AfclOaidfXU0cOGg3ytJ2j6D7ki4N3D7DOfuBGZdJyvJ2cDBwG5JNgIn0sy62hG4rJ2Ne2U74+qFwJ8leQDYAry5qqYG4N9CM6NrJ5oxk95xE0nSPBg0gfyMmQesl9B2Oc2kqlb2Kf7kDHXPA86b4dxaYP/Zvmsh6+1W2nDyYUP/TEmCwbuwvgr8UZIdewvb9+9sz0uSFoBBWyAn0Sxb8q0kf0vzXMhi4HeBXYE3DDM4SdL4GnQa7/VJXgT8Jc3A96OAB4GvAb9TVdcPP0RJ0jgatAVCVV0NvDDJTsAuwI+q6udDj0ySNNYGTiBT2qRh4pCkBWrgBNI+k/Eamim9j5t2utol3iVJj3CDPol+OM16WI8C7uHh03ZdKkSSFohBWyD/B7gceF1VuTKhJC1ggyaQpwHvNHlIkgZ9kPCbNM97SJIWuEFbIH8MfDDJVVV151wEpOFyCRJJc6XLk+i7ArcmuZ1puwvSzML6r8MITJI03gZNIFto9kKXJC1wgy5lcvAcxSFJmjBd9i2XJGnwBJJkcZL3J1mbZH2S/dvydyR57vBDlCSNo4ESSJL9gBuB19PsQ7438Nj29FOBtw81OknS2Bq0BXIKcCuwDHgVkJ5z/wQcNKS4JEljbtBZWM8HVlbVT5PsMO3c3cCThxOWJGncDdoCeXCWc7uxleXdk5ye5J4kN/WUPSnJZUlub3/u0nPuhCTrktyW5JCe8gOS3NieOzVJpn+XJGluDZpArgbeOMO51wD/uJXrzwAOnVZ2PPClqtoH+FL7niT7AkcB+7XXfKSn1XMasArYp31N/0xJ0hwbNIH8OfDfklxKM5BewEuTnAkcCaye7eKq+goPf3r9cODM9vhM4Iie8nOq6v6qWg+sAw5Msiewc1VdUVUFnNVzjSRpngyUQKrqyzR/rJcBp9MMop8MvAA4oqqu6hDDHlW1qf38TcDubfli4Ls99Ta2ZYvb4+nlfSVZ1U45Xrt5s4sIS9KwdNkT/WLg4iTPoPljf29VzcXyJv3GNWqW8r6qag2wBmDFihVueCVJQ7I9e6Kvo+lW2l53J9mzqja13VP3tOUbgb166i2hefZkY3s8vVySNI8G3dL26K3VqaqzBozhIuAYmq6wY4ALe8o/neT9wFNoBsuvrqotSe5LchBwFXA08KEBv1OStJ0GbYGcMUN5b9fQjAkkydnAwcBuSTYCJ9IkjnOTHAt8B3g1QFXdnORc4BbgAeC4qtrSftRb2lh2Aj7fviRJ82jQBLKsT9muwG8D/wP43dkurqqVM5x6yQz1V9NnZldVrQX2nzVSSdKcGnQ592/3Kf42cG37MN8f0iQSSdIj3DCXc/8qcNgQP0+SNMaGmUAOAn46xM+TJI2xQWdhvadP8WNpxiMOAz48jKAkSeNv0EH0k/qU3U8zDrIa+H/bG5AkaTIMOojuFriSJMA90SVJHQ06BrL3IPWr6juDhSNJ423p8Rc/dLzh5IU98XTQMZANzLJwYR/Tdy2UJD1CDJpA3gK8G/gJcC6/2Mb2NcATaAbS7x9mgJKk8TRoAnkWcC1wZLuZEwBJ/gy4AHhWVf3B8MKTJI2rQQfRVwIf600eAO37j+IyJpK0YAyaQJ4ALJrh3O7A47cvHEnSpBg0gVwO/N8kv9FbmORAmvGPy4cTliRp3A2aQN5KM0h+ZZINSa5KsgG4AvjX9rwkaQEY9En09Ul+DXgDzeKJewI30SSQM6vq34ceoSRpLA28J3qbJD7eviRJC9TACQQgybOBF9LsRvixqvp+kmcAd1fVfcMMUJI0ngYaA0myY5LPAt8ATgXeAzylPf0+mocMB5bkV5Nc1/P6SZJ3JDkpyfd6yl/Rc80JSdYluS3JIV2+V5LU3aCD6KuBlwKvB/YA0nPu80CnP+RVdVtVLa+q5cABwM+A89vTH5g6V1WXACTZFzgK2A84FPhIEpdNkaR51OVBwv9dVZ8Gfjjt3Hpg6RBieglwxwz7r085HDinqu6vqvXAOuDAIXy3JGkbDToGsitw6wznHgXsuH3hAE3L4uye929NcjSwFnhnVf0IWAxc2VNnY1v2MElWAasA9t57oMWEx5orgkoatUFbIOuB/zLDuQOB27YnmCSPBV4JfLYtOg14OrAc2AScMlW1z+V9VwmuqjVVtaKqVixaNNND9JKkQQ2aQM4Cjk/yOpq90AEqyYuAPwBO3854Xg5cW1V3A1TV3VW1paoepJk2PNVNtRHYq+e6JcBd2/ndkqQBDJpA3gdcDPwNvxgD+RrwReDvq+pD2xnPSnq6r5Ls2XPuSJqHFgEuAo5qZ4UtA/YBrt7O75YkDWDQJ9G30Pzh/muaGVe7A/fSJI8vb08gSf4D8FvAm3qK35dkOU331Iapc1V1c5JzgVuAB4Dj2tgWpN7xEEmaL9ucQNrxiSuB46vqUuCrwwykqn5GM0jfW/b6WeqvpplWLEkagW3uwqqqfwOW0fwfvyRpgRt0DOQy4GVzEYgkabIM+hzIh4C/TfJomi1sNzFt+mxV3Tmc0CRJ42zQBDI1UP6HNNN2+3FJEUlaALaaQJK8GLi6qn4K/B4zPLAnSVpYtqUFchnN0+dXV9UZSR5Fs3XtsVV1+1wGJ0kaX9syiD592ZAAzweeOPxwJEmTYtBZWJIkASYQSVJH2zoLa3GSp7XHO/SU/fP0ik7jlaSFYVsTyN/1KbtghrpO45WkBWBbEsgb5zwKSdLE2WoCqaoz5yMQSdJkcRBdktSJCUSS1IkJRJLUiQlEktSJCUSS1IkJRJLUydgkkCQbktyY5Loka9uyJyW5LMnt7c9deuqfkGRdktuSHDK6yCVpYRqbBNJ6UVUtr6oV7fvjgS9V1T7Al9r3JNkXOArYDzgU+EgSn4CXpHk0bglkusOBqQcZzwSO6Ck/p6rur6r1wDrgwPkPT5IWrnFKIAVcmuSaJKvasj2qahNA+3P3tnwx8N2eaze2ZQ+TZFWStUnWbt68eY5Cl6SFZ9A90efS86rqriS7A5cl+eYsdadvcgUzbLVbVWuANQArVqxwO15JGpKxaYFU1V3tz3uA82m6pO5OsidA+/OetvpGYK+ey5cAd81ftJKksUggSR6f5IlTx8DLgJuAi4Bj2mrHABe2xxcBRyXZMckyYB/g6vmNWpIWtnHpwtoDOD8JNDF9uqr+PsnXgXOTHAt8B3g1QFXdnORc4BbgAeC4qtoymtAlaWEaiwTS7mL4n/uU3wu8ZIZrVgOr5zg0SdIMxiKBaNssPf7iUYcgSQ8ZizEQSdLksQUy5mx1SBpXtkAkSZ2YQCRJndiFpTnR2/W24eTDRhiJpLliC0SS1IkJRJLUiQlEktSJCUSS1IkJRJLUibOwxoSzliRNGlsgkqRObIHMM1sakh4pbIFIkjoxgUiSOjGBSJI6MYFIkjoZi0H0JHsBZwFPBh4E1lTVXyU5CfifwOa26p9U1SXtNScAxwJbgN+vqi/Me+Dbaaa9PtwDRNIkGIsEAjwAvLOqrk3yROCaJJe15z5QVX/ZWznJvsBRwH7AU4AvJnlmVW2Z16glaQEbiy6sqtpUVde2x/cBtwKLZ7nkcOCcqrq/qtYD64AD5z5SSdKUsUggvZIsBX4duKotemuSG5KcnmSXtmwx8N2eyzYyQ8JJsirJ2iRrN2/e3K+KJKmDsUogSZ4AnAe8o6p+ApwGPB1YDmwCTpmq2ufy6veZVbWmqlZU1YpFixYNP2hJWqDGJoEkeQxN8vhUVX0OoKrurqotVfUg8HF+0U21Edir5/IlwF3zGa8kLXRjkUCSBPgkcGtVvb+nfM+eakcCN7XHFwFHJdkxyTJgH+Dq+YpXkjQ+s7CeB7weuDHJdW3ZnwArkyyn6Z7aALwJoKpuTnIucAvNDK7jnIElSfNrLBJIVX2N/uMal8xyzWpg9ZwFJUma1Vh0YUmSJo8JRJLUiQlEktSJCUSS1IkJRJLUyVjMwpKkSbTQt6i2BSJJ6sQWyDxwfw9Jj0S2QCRJnZhAJEmdmEAkSZ2YQCRJnZhAJEmdmEAkSZ2YQCRJnZhAJEmd+CChJA3BQlzWxBaIJKkTE4gkqZOJ7sJKcijwV8AOwCeq6uQRh/QQ17+SFq6F0p01sS2QJDsAfw28HNgXWJlk39FGJUkLx8QmEOBAYF1V3VlV/wacAxw+4pgkacGY5C6sxcB3e95vBJ47vVKSVcCq9u1Pk9zW8ft2A37Q8dr5Nlax5r1brTJW8W7FJMUKkxXvJMUK2xjvNvz7Px+2994+tV/hJCeQ9CmrhxVUrQHWbPeXJWurasX2fs58mKRYYbLinaRYYbLinaRYYbLinatYJ7kLayOwV8/7JcBdI4pFkhacSU4gXwf2SbIsyWOBo4CLRhyTJC0YE9uFVVUPJHkr8AWaabynV9XNc/iV290NNo8mKVaYrHgnKVaYrHgnKVaYrHjnJNZUPWzYQJKkrZrkLixJ0giZQCRJnZhAtiLJoUluS7IuyfGjjqefJBuS3JjkuiRr27InJbksye3tz11GFNvpSe5JclNP2YyxJTmhvde3JTlkTOI9Kcn32vt7XZJXjEO8SfZK8g9Jbk1yc5K3t+VjeX9niXfs7m+SxyW5Osn1bax/2paP3b2dJda5v69V5WuGF83g/B3A04DHAtcD+446rj5xbgB2m1b2PuD49vh44L0jiu2FwHOAm7YWG82SNNcDOwLL2nu/wxjEexLwv/rUHWm8wJ7Ac9rjJwLfamMay/s7S7xjd39pnjN7Qnv8GOAq4KBxvLezxDrn99UWyOwmebmUw4Ez2+MzgSNGEURVfQX44bTimWI7HDinqu6vqvXAOpp/BvNmhnhnMtJ4q2pTVV3bHt8H3EqzQsNY3t9Z4p3JyOKtxk/bt49pX8UY3ttZYp3J0GI1gcyu33Ips/0LPyoFXJrkmnbpFoA9qmoTNP/hAruPLLqHmym2cb7fb01yQ9vFNdVtMTbxJlkK/DrN/32O/f2dFi+M4f1NskOS64B7gMuqamzv7QyxwhzfVxPI7LZpuZQx8Lyqeg7NysTHJXnhqAPqaFzv92nA04HlwCbglLZ8LOJN8gTgPOAdVfWT2ar2KRuHeMfy/lbVlqpaTrPKxYFJ9p+l+jjGOuf31QQyu4lYLqWq7mp/3gOcT9McvTvJngDtz3tGF+HDzBTbWN7vqrq7/Q/0QeDj/KK5P/J4kzyG5o/xp6rqc23x2N7ffvGO8/1t4/tn4HLgUMb43sIvxzof99UEMruxXy4lyeOTPHHqGHgZcBNNnMe01Y4BLhxNhH3NFNtFwFFJdkyyDNgHuHoE8f2SqT8YrSNp7i+MON4kAT4J3FpV7+85NZb3d6Z4x/H+JlmU5Ffa452AlwLfZAzv7Uyxzst9nY9ZApP8Al5BM1vkDuDdo46nT3xPo5lRcT1w81SMwK7Al4Db259PGlF8Z9M0n/+d5v98jp0tNuDd7b2+DXj5mMT7N8CNwA3tf3x7jkO8wPNpuh5uAK5rX68Y1/s7S7xjd3+BZwPfaGO6CXhPWz5293aWWOf8vrqUiSSpE7uwJEmdmEAkSZ2YQCRJnZhAJEmdmEAkSZ2YQKQ5kuQTSSrJ+7deW5o8TuOV5kD7QNf3gZ1pnlZeXFUPjDYqabhsgUhz40ia5HEJzYJ7h442HGn4TCDS3DgG+BHwBuDnwNHTKyRZmeSbSf41zYZgr0xyeZLLp9XbLclp7eZA97fXrJr+edJ8e/SoA5AeaZI8hWY9ojVVtTnJBcCrkuxSVT9q6/wW8CmaJSbeCewGfBB4HM3SOVOftTPwj8BONBsErQcOAU5LsmNVfWiefi3pYUwg0vC9nqZ1f1b7/kxgJfBa4KNt2Z8CtwBHVjsQmeRG4Bp6EgjwduCpwH+qqtvbsi+2i+edmOQ0x1Y0KnZhScN3NHB7VV3Rvv8izXLZR0Oz+Q+wAjivemaxVLNb3/ppn3UozaZL65M8euoFfIFmYb995/Q3kWZhC0QaoiS/QfNH/b1TS2y3PkezO9wzgR/TbDvab4+Wu6e93x14Bs3qwP3sul0BS9vBBCIN19ReEe9qX9MdDZxIkxD6bTO8B/Cdnvf30iSat8/wfbd1C1Pafj4HIg1Ju+nYXcA64Pg+VT4APAlYSjMwvjPN2MbUGMgBwFrgy1V1cFt2EvA24FnV7DgpjQ0TiDQkSV5Fs13rG6rqzD7n30yzT/WLaVr/l9LsaLeGZhbWSTSzrW6tqhe31/xH4Eqa8coP0LQ4Hg/8GvCCqjp8bn8raWYOokvDcwxwH/DZGc6fTfNMyDFVdRnwOuBZNPvYv4tmOu/3acZIAKiqHwO/SfNA4rtoBs9PBw4H/mFOfgtpG9kCkcZEkiU03V+rq+rPRx2PtDUmEGkE2rWy3k8zxfcHNHvb/zHNIPp+VbVphOFJ28RZWNJobAGeDHyYZiruvwBfBV5t8tCksAUiSerEQXRJUicmEElSJyYQSVInJhBJUicmEElSJ/8flDeOvU8gXbwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select appropiate columns from the training set to find date difference\n",
    "data_age = data1[['DOB', 'ADMITTIME']]\n",
    "\n",
    "# We convert the relevant columns to standard date time represent them in a dataframe \n",
    "data_age_dob= pd.to_datetime(data_age['DOB'])\n",
    "data_age_adm= pd.to_datetime(data_age['ADMITTIME'])\n",
    "data_age_dob = pd.DataFrame(data_age_dob)\n",
    "data_age_adm = pd.DataFrame(data_age_adm)\n",
    "\n",
    "# Extract the year of each of the relevant columns\n",
    "data_age_dob['Age'] = pd.DatetimeIndex(data_age_dob.iloc[:,0]).year\n",
    "data_age_adm['Age'] = pd.DatetimeIndex(data_age_adm.iloc[:,0]).year\n",
    "\n",
    "# Perform the subtraction to find the age and load it into a dataframe\n",
    "data_diff = data_age_adm['Age']-data_age_dob['Age']\n",
    "data_diff=pd.DataFrame(data_diff )\n",
    "\n",
    "# Represent the Age in a histogram\n",
    "plt.xlabel(\"Age\", fontsize=16)\n",
    "plt.ylabel(\"Frequency\", fontsize=16)\n",
    "plt.hist(data_diff,bins=100,range=[0, 350],label='AGE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can witness from the histogram, there are some values above 300 that are not plausible. After some online investigation we discovered that \"age for patients older than eighty-nine is masked as 300 in MIMIC- III for privacy reasons\". Therefore, we firstly found the difference between the implausible ages and 89 and secondly subtracted to each implausible value the obtained difference in the preceeding step. The result is a sensible histogram for age distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter for ages below 100 and obtain the maximum value to certify its 89\n",
    "below_100 = data_diff[data_diff['Age']<100]\n",
    "below_100.max()\n",
    "\n",
    "# Filter for ages above 100 and obtain the min which should be 300 (histogram)\n",
    "above_100 = data_diff[data_diff['Age']>100]\n",
    "above_100.min()\n",
    "\n",
    "# Subtract to each age above 100 the difference between 300 and 89 \n",
    "data_diff['Age'] = np.where(data_diff['Age'] >100 , data_diff['Age'] - (300-89), data_diff['Age'])\n",
    "\n",
    "# plot histogram with appropiate labels to certify a sensible age distribution was obtained\n",
    "plt.xlabel(\"Age\", fontsize=16)\n",
    "plt.ylabel(\"Frequency\", fontsize=16)\n",
    "plt.hist(data_diff,bins=100,range=[0, 350])\n",
    "plt.show()\n",
    "\n",
    "# Merge the new age column in our training set\n",
    "data2= pd.concat([data1,data_diff],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analogous procedure was performed in the test set to obtain the corresponding age of each patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select appropiate columns from the test set to find date difference\n",
    "data_age1 = X_test1[['DOB', 'ADMITTIME']]\n",
    "\n",
    "# We convert the relevant columns to standard date time and represent them in a dataframe \n",
    "data_age_dob1= pd.to_datetime(data_age1['DOB'])\n",
    "data_age_adm1= pd.to_datetime(data_age1['ADMITTIME'])\n",
    "data_age_dob1 = pd.DataFrame(data_age_dob1)\n",
    "data_age_adm1 = pd.DataFrame(data_age_adm1)\n",
    "\n",
    "# Extract the year of each of the relevant columns\n",
    "data_age_dob1['Age'] = pd.DatetimeIndex(data_age_dob1.iloc[:,0]).year\n",
    "data_age_adm1['Age'] = pd.DatetimeIndex(data_age_adm1.iloc[:,0]).year\n",
    "\n",
    "# Perform the subtraction to find the age and load it into a dataframe\n",
    "data_diff1 = data_age_adm1['Age']-data_age_dob1['Age']\n",
    "data_diff1=pd.DataFrame(data_diff1)\n",
    "\n",
    "# Represent the Age in a histogram\n",
    "plt.xlabel(\"Age\", fontsize=16)\n",
    "plt.ylabel(\"Frequency\", fontsize=16)\n",
    "plt.hist(data_diff1,bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the same problem we had with age in the training set arises in the test set, we adopt the same strategy to deal with the inconsistencies. As we witness in the new histogram, the age distribution is now adequately represented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter for ages below 100 and obtain the maximum value to certify its 89\n",
    "below_100_ = data_diff1[data_diff1['Age']<100]\n",
    "below_100_.max()\n",
    "\n",
    "# Filter for ages above 100 and obtain the min which should be from histogram 300\n",
    "above_100_ = data_diff1[data_diff1['Age']>100]\n",
    "above_100_.min()\n",
    "\n",
    "# Subtract to each age above 100 the difference between the minimum age above 100 and 89\n",
    "data_diff1['Age'] = np.where(data_diff1['Age'] >100 , data_diff1['Age'] - (300-89), data_diff1['Age'])\n",
    "data_diff1.max()\n",
    "\n",
    "# Plot histogram with appropiate labels to certify a sensible age distribution was obtained\n",
    "plt.xlabel(\"Age\", fontsize=16)\n",
    "plt.ylabel(\"Frequency\", fontsize=16)\n",
    "plt.hist(data_diff1,bins=100,range=[0, 350])\n",
    "plt.show()\n",
    "\n",
    "# Merge the new age column in our test set\n",
    "X_test2= pd.concat([X_test1,data_diff1],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Combining Religion & Ethnicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are high cardinality categorical features with few observsations in some categories. We can combine them to reduce the number of dummy variables we have to produce in one-hot enconding to be applied to unordered categorial features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count values for features per category\n",
    "data2['ETHNICITY'].value_counts()\n",
    "data2['RELIGION'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We edit ethnicity on out trianing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combing Ethnicity (train set)\n",
    "data2['ETHNICITY'] = data2['ETHNICITY'].replace(['ASIAN', 'ASIAN - CHINESE', 'ASIAN - ASIAN INDIAN', 'ASIAN - VIETNAMESE', 'ASIAN - FILIPINO', 'ASIAN - CAMBODIAN',\n",
    "                                                     'ASIAN - JAPANESE', 'ASIAN - THAI', 'ASIAN - OTHER', 'ASIAN - KOREAN'\n",
    "                                                     ], 'ASIAN')\n",
    "\n",
    "data2['ETHNICITY'] = data2['ETHNICITY'].replace(['HISPANIC 0R LATINO', 'HISPANIC/LATINO - PUERTO RICAN', 'HISPANIC/LATINO - DOMINICAN',\n",
    "                                                     'HISPANIC/LATINO - GUATEMALAN', 'HISPANIC/LATINO - CUBAN', 'HISPANIC/LATINO - SALVADORAN',\n",
    "                                                     'HISPANIC/LATINO - MEXICAN', 'HISPANIC/LATINO - CENTRAL AMERICAN (OTHER)', 'HISPANIC/LATINO - COLOMBIAN',\n",
    "                                                     'HISPANIC/LATINO - HONDURAN', 'SOUTH AMERICAN'\n",
    "                                                     ], 'HISPANIC OR LATINO')\n",
    "\n",
    "data2['ETHNICITY'] = data2['ETHNICITY'].replace(['WHITE', 'WHITE - RUSSIAN', 'WHITE - OTHER EUROPEAN', 'WHITE - EASTERN EUROPEAN',\n",
    "                                                     'WHITE - BRAZILIAN'\n",
    "                                                     ], 'WHITE')\n",
    "\n",
    "data2['ETHNICITY'] = data2['ETHNICITY'].replace(['BLACK/AFRICAN', 'BLACK/AFRICAN AMERICAN', 'BLACK/CAPE VERDEAN', 'BLACK/HAITIAN'\n",
    "                                                     ], 'BLACK')\n",
    "\n",
    "data2['ETHNICITY'] = data2['ETHNICITY'].replace(['UNABLE TO OBTAIN', 'UNKNOWN/NOT SPECIFIED', 'PATIENT DECLINED TO ANSWER'\n",
    "                                                     ], 'UNKNOWN')\n",
    "\n",
    "data2['ETHNICITY'] = data2['ETHNICITY'].replace(['AMERICAN INDIAN/ALASKA NATIVE', 'AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE',\n",
    "                                                     'CARIBBEAN ISLAND', 'MIDDLE EASTERN', 'OTHER', 'PORTUGUESE', 'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER',\n",
    "                                                     'MULTI RACE ethnicity'\n",
    "                                                      ], 'OTHER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the analogous in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combing Ethnicity (test set)\n",
    "X_test2['ETHNICITY'] = X_test2['ETHNICITY'].replace(['ASIAN', 'ASIAN - CHINESE', 'ASIAN - ASIAN INDIAN', 'ASIAN - VIETNAMESE', 'ASIAN - FILIPINO', 'ASIAN - CAMBODIAN',\n",
    "                                                     'ASIAN - JAPANESE', 'ASIAN - THAI', 'ASIAN - OTHER', 'ASIAN - KOREAN'\n",
    "                                                     ], 'ASIAN')\n",
    "\n",
    "X_test2['ETHNICITY'] = X_test2['ETHNICITY'].replace(['HISPANIC 0R LATINO', 'HISPANIC/LATINO - PUERTO RICAN', 'HISPANIC/LATINO - DOMINICAN',\n",
    "                                                     'HISPANIC/LATINO - GUATEMALAN', 'HISPANIC/LATINO - CUBAN', 'HISPANIC/LATINO - SALVADORAN',\n",
    "                                                     'HISPANIC/LATINO - MEXICAN', 'HISPANIC/LATINO - CENTRAL AMERICAN (OTHER)', 'HISPANIC/LATINO - COLOMBIAN',\n",
    "                                                     'HISPANIC/LATINO - HONDURAN', 'SOUTH AMERICAN'\n",
    "                                                     ], 'HISPANIC OR LATINO')\n",
    "\n",
    "X_test2['ETHNICITY'] = X_test2['ETHNICITY'].replace(['WHITE', 'WHITE - RUSSIAN', 'WHITE - OTHER EUROPEAN', 'WHITE - EASTERN EUROPEAN',\n",
    "                                                     'WHITE - BRAZILIAN'\n",
    "                                                     ], 'WHITE')\n",
    "\n",
    "X_test2['ETHNICITY'] = X_test2['ETHNICITY'].replace(['BLACK/AFRICAN', 'BLACK/AFRICAN AMERICAN', 'BLACK/CAPE VERDEAN', 'BLACK/HAITIAN'\n",
    "                                                     ], 'BLACK')\n",
    "\n",
    "X_test2['ETHNICITY'] = X_test2['ETHNICITY'].replace(['UNABLE TO OBTAIN', 'UNKNOWN/NOT SPECIFIED', 'PATIENT DECLINED TO ANSWER'\n",
    "                                                     ], 'UNKNOWN')\n",
    "\n",
    "X_test2['ETHNICITY'] = X_test2['ETHNICITY'].replace(['AMERICAN INDIAN/ALASKA NATIVE', 'AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE',\n",
    "                                                     'CARIBBEAN ISLAND', 'MIDDLE EASTERN', 'OTHER', 'PORTUGUESE', 'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER',\n",
    "                                                     'MULTI RACE ethnicity'\n",
    "                                                      ], 'OTHER')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We certify the changes have been implemented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WHITE                   3849\n",
       "BLACK                    532\n",
       "UNKNOWN                  352\n",
       "HISPANIC OR LATINO       203\n",
       "ASIAN                    144\n",
       "OTHER                    129\n",
       "MULTI RACE ETHNICITY      12\n",
       "Name: ETHNICITY, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count values for features per category\n",
    "data2['ETHNICITY'].value_counts()\n",
    "X_test2['ETHNICITY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We preprocess religion on both the train and test set, grouping those with few observations into an \"other\" category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combing Religion (train set)\n",
    "\n",
    "religion_other = ['HEBREW', 'UNITARIAN-UNIVERSALIST', 'HINDU', 'GREEK ORTHODOX',\"JEHOVAH'S WITNESS\", \"BUDDHIST\", 'MUSLIM', 'OTHER', 'CHRISTIAN SCIENTIST', 'EPISCOPALIAN', 'ROMANIAN EAST. ORTH', '7TH DAY ADVENTIST']\n",
    "data2['RELIGION'] = data2['RELIGION'].replace(religion_other, 'OTHER')\n",
    "\n",
    "# Combing Religion (test set)\n",
    "\n",
    "X_test2['RELIGION'] = X_test2['RELIGION'].replace(religion_other, 'OTHER')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We certify changes have been implemented appropiately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CATHOLIC             1898\n",
       "NOT SPECIFIED        1361\n",
       "PROTESTANT QUAKER     697\n",
       "JEWISH                446\n",
       "OTHER                 424\n",
       "UNOBTAINABLE          395\n",
       "Name: RELIGION, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count values for features per category\n",
    "data2['RELIGION'].value_counts()\n",
    "X_test2['RELIGION'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) Repeat visits to ICU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to take advantage of time series structure train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new variable in train and test set\n",
    "data2[\"visits_ICU\"] = data2.sort_values(['subject_id', 'ADMITTIME']).groupby([\"subject_id\"]).cumcount() + 1\n",
    "X_test2[\"visits_ICU\"] = X_test2.sort_values(['subject_id', 'ADMITTIME']).groupby([\"subject_id\"]).cumcount() + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify new feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore recent created feature\n",
    "data2[\"visits_ICU\"] = data2.sort_values(['subject_id', 'ADMITTIME']).groupby([\"subject_id\"]).cumcount() + 1\n",
    "X_test2[\"visits_ICU\"] = X_test2.sort_values(['subject_id', 'ADMITTIME']).groupby([\"subject_id\"]).cumcount() + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D) Number of comorobilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another potentially useful information implicitely present in the metadata is the number of co-morbilities. We would like to include this feature as an explanatory variable both on the training set and test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure our metadata column names have been renamed appropiately for compatibility with training set\n",
    "X_metadata = X_metadata.rename(columns={'SUBJECT_ID':'subject_id'})\n",
    "X_metadata = X_metadata.rename(columns={'HADM_ID':'hadm_id'})\n",
    "\n",
    "# Group our metadata by subject_id and hadm_id and count the number of comorbilities indicated by the column SEQ_NUM\n",
    "X_metadata2 = X_metadata.groupby(['subject_id','hadm_id'],as_index=False)['SEQ_NUM'].count()\n",
    "\n",
    "# Merge our newly created variable with training set using subject_id and hadm_id as keys\n",
    "data3 = data2.merge(X_metadata2,how='left',on=['subject_id','hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogously, we add the newly created explanatory variable to the corresponding patients in the test set, using -as in the trainig set merge- subject_id and hadm_id as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge test set with metadata to conform the new test set using subject_id and hadm_id as keys\n",
    "X_test3 = X_test2.merge(X_metadata2,how='left',on=['subject_id','hadm_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Train Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furtermore, we explicitely separate our training set covariates, our training set target variable and our test set covariates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select explanatory variables from traing data\n",
    "X_train = data3.drop([\"LOS\"],axis=1)\n",
    "\n",
    "# Select target variable from traing data\n",
    "y_train = data3[[\"LOS\"]]\n",
    "\n",
    "# Load test set covariates in a data frame\n",
    "X_test = pd.DataFrame(X_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4) Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we contemplate the possibility of excluding outliers that are beyond 3 standard deviations from the mean. We only analyze some numerical variables in the training set for potencial outlier exclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove outliers from a particular dataframe column\n",
    "def subset_by_iqr(df, column, whisker_width):\n",
    "    \"\"\"Remove outliers from a dataframe by column, including optional\n",
    "       whiskers, removing rows for which the column value are\n",
    "       less than Q1-1.5IQR or greater than Q3+1.5IQR.\n",
    "    Args:\n",
    "        df (`:obj:pd.DataFrame`): A pandas dataframe to subset\n",
    "        column (str): Name of the column to calculate the subset from.\n",
    "        whisker_width (float): Optional, loosen the IQR filter by a\n",
    "                               factor of `whisker_width` * IQR.\n",
    "    Returns:\n",
    "        (`:obj:pd.DataFrame`): Filtered dataframe\n",
    "    \"\"\"\n",
    "    # Calculate Q1, Q2 and IQR\n",
    "    q1 = df[column].quantile(0.25)\n",
    "    q3 = df[column].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    # Apply filter with respect to IQR, including optional whiskers\n",
    "    filter = (df[column] >= q1 - whisker_width*iqr) & (df[column] <= q3 + whisker_width*iqr)\n",
    "    return df.loc[filter]\n",
    "\n",
    "\n",
    "# Exclude outliers that are beyond 3 std from the mean for some numerical variables in training set\n",
    "data_outliers = subset_by_iqr(X_train, column='HeartRate_Min', whisker_width=3)\n",
    "data_outliers = subset_by_iqr(data_outliers, column='HeartRate_Max', whisker_width=3)\n",
    "\n",
    "data_outliers = subset_by_iqr(data_outliers, column='SysBP_Min', whisker_width=3)\n",
    "data_outliers = subset_by_iqr(data_outliers, column='SysBP_Max', whisker_width=3)\n",
    "\n",
    "data_outliers = subset_by_iqr(data_outliers, column='DiasBP_Min', whisker_width=3)\n",
    "data_outliers = subset_by_iqr(data_outliers, column='DiasBP_Max', whisker_width=3)\n",
    "\n",
    "data_outliers = subset_by_iqr(data_outliers, column='MeanBP_Min', whisker_width=3)\n",
    "data_outliers = subset_by_iqr(data_outliers, column='MeanBP_Max', whisker_width=3)\n",
    "\n",
    "data_outliers = subset_by_iqr(data_outliers, column='RespRate_Min', whisker_width=3)\n",
    "data_outliers = subset_by_iqr(data_outliers, column='RespRate_Max', whisker_width=3)\n",
    "\n",
    "data_outliers = subset_by_iqr(data_outliers, column='TempC_Min', whisker_width=3)\n",
    "data_outliers = subset_by_iqr(data_outliers, column='TempC_Max', whisker_width=3)\n",
    "\n",
    "data_outliers = subset_by_iqr(data_outliers, column='SpO2_Min', whisker_width=3)\n",
    "data_outliers = subset_by_iqr(data_outliers, column='SpO2_Max', whisker_width=3)\n",
    "\n",
    "data_outliers = subset_by_iqr(data_outliers, column='Glucose_Min', whisker_width=3)\n",
    "data_outliers = subset_by_iqr(data_outliers, column='Glucose_Max', whisker_width=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The impact on performance metrics provoked by the exclusion of outliers was assesed for different values of the whisker width. As outlier exclusion didn't have a significant impact on subsequent used performance metrics -it even worsen simulated predictions assesed by cross-validation- we opted to keep rare extreme values in our training set. This may seem sensible as extreme values in one variable may provide some valuable information regarding the lenghth of stay. In short, the evidence suggested it was convenient to keep outliers in our training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Strucural missing data: marital status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine nan values for marital status with the UNKNOWN class. As there is not an unknown class we add a 'missing' class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes in feature marital status\n",
    "X_train[\"MARITAL_STATUS\"].unique()\n",
    "\n",
    "# We deal with marital status missing\n",
    "X_train['MARITAL_STATUS'] = X_train['MARITAL_STATUS'].fillna('UNKNOWN (DEFAULT)')\n",
    "X_test['MARITAL_STATUS'] = X_test['MARITAL_STATUS'].fillna('UNKNOWN (DEFAULT)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) Foward and Backweard filling with previous visit information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again take advantage of time series data to foward fill and back fill thee patients that come repetedly with the information of their previpous visit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foward filling train and test set\n",
    "X_trainA = X_train.groupby(['subject_id'], as_index = False).apply(lambda group: group.ffill())\n",
    "X_testA = X_test.groupby(['subject_id'], as_index = False).apply(lambda group: group.ffill())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check missing values train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject_id          0\n",
       "hadm_id             0\n",
       "icustay_id          0\n",
       "HeartRate_Min     521\n",
       "HeartRate_Max     521\n",
       "HeartRate_Mean    521\n",
       "SysBP_Min         527\n",
       "SysBP_Max         527\n",
       "SysBP_Mean        527\n",
       "DiasBP_Min        528\n",
       "DiasBP_Max        528\n",
       "DiasBP_Mean       528\n",
       "MeanBP_Min        523\n",
       "MeanBP_Max        523\n",
       "MeanBP_Mean       523\n",
       "RespRate_Min      522\n",
       "RespRate_Max      522\n",
       "RespRate_Mean     522\n",
       "TempC_Min         609\n",
       "TempC_Max         609\n",
       "TempC_Mean        609\n",
       "SpO2_Min          526\n",
       "SpO2_Max          526\n",
       "SpO2_Mean         526\n",
       "Glucose_Min        52\n",
       "Glucose_Max        52\n",
       "Glucose_Mean       52\n",
       "GENDER              0\n",
       "DOB                 0\n",
       "ADMITTIME           0\n",
       "Diff                0\n",
       "ADMISSION_TYPE      0\n",
       "INSURANCE           0\n",
       "RELIGION            0\n",
       "MARITAL_STATUS      0\n",
       "ETHNICITY           0\n",
       "DIAGNOSIS           0\n",
       "ICD9_diagnosis      0\n",
       "FIRST_CAREUNIT      0\n",
       "Age                 0\n",
       "visits_ICU          0\n",
       "SEQ_NUM             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Nulls - train and test\n",
    "X_trainA.isnull().sum()\n",
    "X_testA.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward filling train and test set\n",
    "X_trainB = X_trainA.groupby(['subject_id'], as_index = False).apply(lambda group: group.bfill())\n",
    "X_testB = X_testA.groupby(['subject_id'], as_index = False).apply(lambda group: group.bfill())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check missing values train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject_id          0\n",
       "hadm_id             0\n",
       "icustay_id          0\n",
       "HeartRate_Min     507\n",
       "HeartRate_Max     507\n",
       "HeartRate_Mean    507\n",
       "SysBP_Min         513\n",
       "SysBP_Max         513\n",
       "SysBP_Mean        513\n",
       "DiasBP_Min        514\n",
       "DiasBP_Max        514\n",
       "DiasBP_Mean       514\n",
       "MeanBP_Min        509\n",
       "MeanBP_Max        509\n",
       "MeanBP_Mean       509\n",
       "RespRate_Min      508\n",
       "RespRate_Max      508\n",
       "RespRate_Mean     508\n",
       "TempC_Min         592\n",
       "TempC_Max         592\n",
       "TempC_Mean        592\n",
       "SpO2_Min          512\n",
       "SpO2_Max          512\n",
       "SpO2_Mean         512\n",
       "Glucose_Min        52\n",
       "Glucose_Max        52\n",
       "Glucose_Mean       52\n",
       "GENDER              0\n",
       "DOB                 0\n",
       "ADMITTIME           0\n",
       "Diff                0\n",
       "ADMISSION_TYPE      0\n",
       "INSURANCE           0\n",
       "RELIGION            0\n",
       "MARITAL_STATUS      0\n",
       "ETHNICITY           0\n",
       "DIAGNOSIS           0\n",
       "ICD9_diagnosis      0\n",
       "FIRST_CAREUNIT      0\n",
       "Age                 0\n",
       "visits_ICU          0\n",
       "SEQ_NUM             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Nulls - train and test\n",
    "X_trainB.isnull().sum()\n",
    "X_testB.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D) KNN imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to impute missing values is one of the most importante tasks in the pre processing of the data. We will use k nearest neighbors through KNNImputer in order to impute missing values of a patient. The strategy is to replace a missing value of a specific feature of a given patient A using the records of the set of patients that resemble the most patient A in other recorded features. In other words, imputing missing values by similarity. We will adopt this approach to fill missing values of the reamining continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The natural question that comes up is how many neighbors or similar patients we should consider to fill our missing values. To determine this we assumed a potential standard Knn model (number of neighbors, weights and algorithm exogenous) and fed it with different possible values of number of neighbors. This procedure will suggest the optimal number of neighbors to use to impute our missing values. Cross validation is used to asses predictive capacity of the model for the different possible neighbors and criteria of optimality is provided by area under the curve (AUC) performance metric. \n",
    "The following pipeline serves this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KNNImputer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-392771c24a59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define the Knn imputer with the number of neighbors to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcont_imputer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNNImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'KNNImputer' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the Knn imputer with the number of neighbors to use\n",
    "cont_imputer = KNNImputer(n_neighbors=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5) Encoding & Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Catgorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leave one out eccoding for unordered categorical. parse=False prevents OneHotEncoder from outputting a sparse matrix and allowing comptability later down the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categroical variables unordered\n",
    "cat_encoder = ce.LeaveOneOutEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Smoothed Target Encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we target encoded the name of the co-morbilities: recall target encoding involves replacing the “features with a blend of posterior probability of the target given particular categorical value and the prior probability of the target over all the training data\". In simple terms, we replace the categories considering the effect they might have on the target variable. After targeting encoding ICD9_CODE we computed the mean value of ICD9_CODE for each subject_id as a representative measure.\n",
    "Smothing can help deal with cases where very observations had a certain disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targed enconding ICD9\n",
    "icd9_encoder = ce.TargetEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to use a RobustScaler for the continious variabes and StandardScalar for the discrete ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling continuous and discrete features\n",
    "cont_scaler = StandardScaler()\n",
    "cat_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6) Variable Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior step in our analysis is to select those variables that we anticipate have some incidence on the patients probability of survival and dropping the rest. Recall that adding variables that have no explanatory power whatsover generates noise that erodes the capacity of our model to capture the underlying pattern in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Anlyzing linear correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first find the correlation betweeen each feature and our target future to explore which variables might be relevant and undergo a process of variable selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate X train set with y train set to investigate correlations\n",
    "data4 = pd.concat([X_trainB,y_train],axis=1)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = data3.corr()\n",
    "\n",
    "# Represent it in a data frame and select column involving target variable\n",
    "corr = pd.DataFrame(corr[['LOS']])\n",
    "corr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Drop a priori irrelevant columns or unavailable infromation when arriving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is logical, the fact that the patiend dies or survives is not available when the patient arrives, hence we cannot use it as a predictor in our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainB.columns\n",
    "X_train_HEF = X_train[['HOSPITAL_EXPIRE_FLAG']]\n",
    "X_trainC= X_trainB.drop(['subject_id','hadm_id','icustay_id','DOB','ADMITTIME','Diff','HeartRate_Mean',\n",
    "                         'SysBP_Mean','DiasBP_Mean','MeanBP_Mean','RespRate_Mean','TempC_Mean','SpO2_Mean',\n",
    "                          'Glucose_Mean','HOSPITAL_EXPIRE_FLAG'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, those columns that serve the purpose of identifying the patient (subject_id & hadm_id) will have no impact whatsoever in our target variable. We also drop date of birth (DOB) and admission time (ADMITTIME) that were already used to estimate the age and by themselves add no explanatory power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of each of the medical categories (heart rate, sys, dias, etc) measured were dropped: not only they are composed of variables already present in the data (max and min) that precisely capture the presence of lower or upper deviations, but we conjecture that it is the presence of extreme values in a given category what impacts our target variable. In other words, the mean value of each medical category adds no relevant information. This is certified by our correlation column given the correlation of the mean value of a medical category is always below the correlation with either the minimum value or the maximimum value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform the analogous feature selection with the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns in the X test set\n",
    "X_testC = X_testB.drop(['subject_id','hadm_id','icustay_id','DOB','ADMITTIME','Diff','HeartRate_Mean',\n",
    "                         'SysBP_Mean','DiasBP_Mean','MeanBP_Mean','RespRate_Mean','TempC_Mean','SpO2_Mean',\n",
    "                          'Glucose_Mean'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7) Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the ColumnTransformer to allwo for different data preprocessing for differen types of columns\n",
    "\n",
    "Numerical values - RobustScaler() and KNNImputer()\n",
    "Categoricals (not ICD9) - OneHotEncoder() and StandardScaler()\n",
    "ICD9 - TargetEncoder() and StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update list of numerical and categorical features\n",
    "X_trainC.dtypes\n",
    "num_feat = X_trainC.select_dtypes(exclude=['object', 'category']).columns\n",
    "print(num_feat)\n",
    "\n",
    "cat_feat = X_trainC.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "\n",
    "# Make own category for preprocessing 'ICD9_diagnosis'\n",
    "icd9_feat = ['ICD9_diagnosis']\n",
    "cat_feat = cat_feat.drop(['ICD9_diagnosis'])\n",
    "print(cat_feat)\n",
    "print(icd9_feat)\n",
    "\n",
    "# pipeline for numerical data\n",
    "num_preprocessing = make_pipeline(\n",
    "    cont_scaler,\n",
    "    cont_imputer\n",
    "    )\n",
    "\n",
    "# pipeline for categorical data\n",
    "cat_preprocessing = make_pipeline(\n",
    "    cat_encoder,\n",
    "    cat_scaler\n",
    "    )\n",
    "\n",
    "# pipeline for ICD9\n",
    "icd9_preprocessing = make_pipeline(\n",
    "    icd9_encoder,\n",
    "    cat_scaler)\n",
    "\n",
    "# combine preprocessing pipelines using a columnTransformer\n",
    "preprocessing = ColumnTransformer(\n",
    "    [(\"num\", num_preprocessing, num_feat),\n",
    "     (\"cat\", cat_preprocessing, cat_feat),\n",
    "     (\"icd9\", icd9_preprocessing, icd9_feat)\n",
    "     ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8) Reweighing important columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on some subjective judgements, you may wish to upweight some of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnReweighter:\n",
    "  def __init__(self, columns, weight):\n",
    "    self.columns = columns\n",
    "    self.weight = weight\n",
    "\n",
    "  def transform(self, X):\n",
    "    Y = X.copy()\n",
    "    for col in self.columns:\n",
    "      try: \n",
    "        Y[col] = X[col]*self.weight\n",
    "      except:\n",
    "        print(\"Column not in X\")\n",
    "\n",
    "    return Y \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine variables to possibly re weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine columns to reweight to include pipeline\n",
    "reweight_feat = [\"age\", 'ICD9_diagnosis', 'HeartRate_Max','SEQ_NUM']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>Part 3: Models </ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.1) DECISION TREES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a pipeline for training a decision tree regressor model on some data. The pipeline consists of two steps: preprocessing the data using the 'preprocess' transformer, and fitting a decision tree regressor model to the preprocessed data using the 'model' step. The decision tree regressor model uses the 'squared_error' criterion for splitting nodes. We are also setting the display configuration to \"diagram\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature name and Class label\n",
    "feature_names = X_trainC.columns\n",
    "class_label = [\"Length of Stay\"]\n",
    "\n",
    "DT_pipe = Pipeline([\n",
    "        ('preprocess', preprocessing),\n",
    "        ('model', DecisionTreeRegressor(criterion='squared_error'))\n",
    "])\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "DT_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using a grid search to find the best hyperparameters for a decision tree regressor model. The grid search uses cross-validation and parallel processing to evaluate different hyperparameter combinations. The best hyperparameters and corresponding cross-validation score are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the tuning hyperparameter possible values\n",
    "DT_params = {\n",
    "    'model__min_impurity_decrease': [0.01, 0.05, 0.1, 0.2, 0.4, 0.8, 1.0],\n",
    "    'model__max_leaf_nodes': [10, 20, 50, 100, 200],\n",
    "    'model__min_samples_leaf': [1, 5, 10, 20],\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# Set grid search through cross validation\n",
    "# Define the grid search object\n",
    "grid_dt = GridSearchCV(estimator=DT_pipe,\n",
    "                           param_grid=DT_params,\n",
    "                           scoring='neg_root_mean_squared_error',\n",
    "                           cv=2,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "# Fit the grid search object\n",
    "grid_dt.fit(X_trainC, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the above code to estimate the root mean squared prediction error of the best estimator, store the results of the grid search in a data frame, make predictions with the best performing model on the test set, create a data frame with these predictions to submit to Kaggle, and convert the data frame to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean square prediction error estimate of best estimator\n",
    "rmse_cv_dt = -1*grid_dt.best_score_\n",
    "rmse_cv_dt\n",
    "\n",
    "# Store grid search results in a data frame\n",
    "res_dt = pd.DataFrame(grid_dt.cv_results_)\n",
    "\n",
    "# Predictions with best performing models on test set\n",
    "y_pred_bm_dt = grid_dt.predict(X_testC)\n",
    "y_pred_bm_dt = pd.DataFrame(y_pred_bm_dt,columns=[\"LOS_pred\"])\n",
    "\n",
    "# Data frame to submit to kaggle\n",
    "test_predictions_submit_dt = pd.DataFrame({\"icustay_id\": icustay_id.iloc[:,0],\n",
    "                                           \"LOS\": y_pred_bm_dt.iloc[:,0]})\n",
    "#Convert to CSV\n",
    "test_predictions_submit_dt.to_csv(\"predictionDT.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.2) RANDOM FORESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using a pipeline with the 'preprocess' step, which is the ColumnTransformer object defined earlier, followed by the 'RF' step, which is a RandomForestRegressor object with the criterion set to 'squared_error'. This pipeline takes in raw data and applies the preprocessing steps defined in the ColumnTransformer object before using the RandomForestRegressor to fit the model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_pipe = Pipeline([\n",
    "        ('preprocess', preprocessing),\n",
    "        ('RF', RandomForestRegressor(criterion='squared_error'))])\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "RF_pipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following chunk, we are using a pipeline to first preprocess the data using the 'preprocess' transformer and then applying a Random Forest Regressor model on the preprocessed data. The hyperparameters of the Random Forest Regressor model are then tuned using a grid search cross-validation method, with the 'neg_root_mean_squared_error' as the evaluation metric. The code then fits the model to the training data and prints the best parameters and score obtained from the grid search cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the tuning hyperparameter possible values\n",
    "RF_params = {\n",
    "    'RF__bootstrap': [True, False],\n",
    "    'RF__n_estimators': [10, 50, 100, 200],\n",
    "    'RF__max_depth': [5, 10, 20],\n",
    "    'RF__min_samples_leaf': [1, 5, 10],\n",
    "    'RF__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "\n",
    "# Set grid search through cross validation\n",
    "grid_rf = GridSearchCV(RF_pipe, RF_params , scoring ='neg_root_mean_squared_error' ,cv=2,verbose=3,n_jobs=-1)\n",
    "model_rf=grid_rf.fit(X_trainC, y_train)\n",
    "\n",
    "print(\"Best parameter (CV score=%0.3f):\" % grid_rf.best_score_)\n",
    "print(grid_rf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the random forest algorithm to predict the length of stay for patients in an intensive care unit. We are utilizing a grid search and cross-validation to find the best combination of hyperparameters for our model, and we are measuring the performance of the model using the root mean square prediction error (RMSE). We are then using the best model to make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Root mean square prediction error estimate of best estimator\n",
    "rmse_cv_rf = -1*grid_rf.best_score_\n",
    "rmse_cv_rf\n",
    "\n",
    "# Store grid search results in a data frame\n",
    "res_rf = pd.DataFrame(grid_rf.cv_results_)\n",
    "\n",
    "\n",
    "# Predictions with best performing models on test set\n",
    "y_pred_bm_rf = grid_rf.predict(X_testC)\n",
    "y_pred_bm_rfdf = pd.DataFrame(y_pred_bm_rf,columns=[\"LOS_pred\"])\n",
    "\n",
    "# Data frame to submit to kaggle\n",
    "test_predictions_submit_rf = pd.DataFrame({\"icustay_id\": icustay_id.iloc[:,0],\n",
    "                                           \"LOS\": y_pred_bm_rfdf.iloc[:,0]})\n",
    "#Convert to CSV\n",
    "test_predictions_submit_rf.to_csv(\"predictionRF2.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the SHAP library to explain the predictions made by a random forest model on the test set.  We are calculating the SHAP values for the test set and using a bar chart to visualize the contributions of each feature to the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the training data\n",
    "#X_trainC_preprocessed = preprocessing.fit_transform(X_trainC,y_train)\n",
    "#X_testC_preprocessed = preprocessing.transform(X_testC)\n",
    "\n",
    "#import shap\n",
    "# Create the explainer\n",
    "#explainer = shap.TreeExplainer(grid_rf.fit(X_trainC, y_train))\n",
    "\n",
    "# Calculate the SHAP values\n",
    "#shap_values = explainer.shap_values(X_testC_preprocessed)\n",
    "\n",
    "# Initialize the JS visualization\n",
    "#shap.initjs()\n",
    "\n",
    "# Plot the SHAP values\n",
    "#shap.summary_plot(shap_values, X_testC_preprocessed, plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.3) ADAPTIVE BOOSTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a pipeline using the AdaBoostRegressor algorithm from scikit-learn. The pipeline consists of two steps: preprocessing and fitting the data to an AdaBoost regressor model with a decision tree regressor as the base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "AB_pipe = Pipeline([\n",
    "        ('preprocess', preprocessing),\n",
    "        ('AB', AdaBoostRegressor(base_estimator=DecisionTreeRegressor()))])\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "AB_pipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a grid search with cross-validation to tune the hyperparameters of an AdaBoost regressor model. The model is contained in a pipeline with a preprocessing step. The hyperparameters being tuned are the learning rate and the number of estimators, and the possible values for each are specified in the dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the tuning hyperparameters and their possible values\n",
    "AB_params = {\n",
    "    'AB__learning_rate': [0.01, 0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "    'AB__n_estimators': [10, 50, 100, 200, 500, 1000]\n",
    "}\n",
    "\n",
    "# Set grid search through cross validation\n",
    "grid_gb = GridSearchCV(AB_pipe, AB_params , scoring ='neg_root_mean_squared_error' ,cv=2,verbose=3,n_jobs=-1)\n",
    "grid_gb.fit(X_trainC, y_train)\n",
    "\n",
    "print(\"Best parameter (CV score=%0.3f):\" % grid_gb.best_score_)\n",
    "print(grid_gb.best_params_)\n",
    "\n",
    "# Predict using best model\n",
    "y_pred_gb = grid_gb.predict(X_testC)\n",
    "y_pred_gb = pd.DataFrame(y_pred_gb)\n",
    "\n",
    "\n",
    "# Data frame to submit to kaggle\n",
    "test_predictions_submit_gb = pd.DataFrame({\"icustay_id\": icustay_id.iloc[:,0] ,\n",
    "                                           \"LOS\": y_pred_gb.iloc[:,0]})\n",
    "#Convert to CSV\n",
    "test_predictions_submit_gb.to_csv(\"predictionGB.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.4) EXTREME GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost is a library for implementing gradient boosting algorithms, which are a type of ensemble model that combines the predictions of multiple weak models to make a strong prediction. One key difference between the XGBoost model and the AdaBoost model is that XGBoost uses decision tree base models, while AdaBoost can use any type of base model.\n",
    "The XGBoost model in this code is contained in a pipeline with a preprocessing step, similar to the pipeline created for the AdaBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Create a pipeline for the XGBoost model\n",
    "XGB_pipe = Pipeline([\n",
    "        ('preprocess', preprocessing),\n",
    "        ('XGB', XGBRegressor(objective='reg:squarederror'))])\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "XGB_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code is defining a grid search with cross-validation to tune the hyperparameters of an XGBoost model. The model is contained in a pipeline with a preprocessing step. The hyperparameters being tuned are the learning rate, maximum depth, and number of estimators.\n",
    "Once the grid search is complete, the best combination of hyperparameters is printed and the best model is used to make predictions on the test set. The RMSE of the best estimator is also calculated and stored, and the results of the grid search are stored in a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the tuning hyperparameters and their possible values\n",
    "XGB_params = {\n",
    "    'XGB__learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
    "    'XGB__max_depth': [1, 3, 5, 7, 9],\n",
    "    'XGB__n_estimators': [10, 50, 100, 250]\n",
    "}\n",
    "\n",
    "# Set grid search through cross validation\n",
    "grid_xgb = GridSearchCV(XGB_pipe, XGB_params , scoring='neg_root_mean_squared_error' ,cv=2,verbose=3,n_jobs=-1)\n",
    "grid_xgb.fit(X_trainC, y_train)\n",
    "\n",
    "print(\"Best parameter (CV score=%0.3f):\" % grid_xgb.best_score_)\n",
    "print(grid_xgb.best_params_)\n",
    "\n",
    "# Root mean square prediction error estimate of best estimator\n",
    "rmse_cv_xgb = -1*grid_xgb.best_score_\n",
    "rmse_cv_xgb\n",
    "\n",
    "# Store grid search results in a data frame\n",
    "res_xgb = pd.DataFrame(grid_xgb.cv_results_)\n",
    "\n",
    "# Predictions with best performing model on test set\n",
    "y_pred_bm_xgb = grid_xgb.predict(X_testC)\n",
    "y_pred_bm_xgb = pd.DataFrame(y_pred_bm_xgb,columns=[\"LOS_pred\"])\n",
    "\n",
    "# Data frame to submit to kaggle\n",
    "test_predictions_submit_xgb = pd.DataFrame({\"icustay_id\": icustay_id.iloc[:,0] ,\n",
    "                                           \"LOS\": y_pred_bm_xgb.iloc[:,0]})\n",
    "\n",
    "#Convert to CSV\n",
    "test_predictions_submit_xgb.to_csv(\"predictionXGB.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.5) NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is using the Keras library from TensorFlow to build and train a neural network for regression. The neural network is defined using the Sequential model from Keras, which consists of a linear stack of layers. The model has two layersand uses the ReLU activation function for the first layer and the linear activation function for the second layer. The model is contained in a pipeline with a preprocessing step, similar to the pipelines created for the AdaBoost and XGBoost models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=16, activation='relu', input_dim=X_trainC.shape[1]))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# Define the model\n",
    "model = KerasRegressor(build_fn=build_model)\n",
    "\n",
    "\n",
    "NN_pipe = Pipeline([\n",
    "        ('preprocess', preprocessing),\n",
    "        ('model', model)])\n",
    "\n",
    "# Set the hyperparameters to tune and their possible values\n",
    "param_grid = {\n",
    "    'model__batch_size': [16, 32, 64, 128, 256],\n",
    "    'model__epochs': [10, 50, 100, 200, 500]\n",
    "}\n",
    "\n",
    "# Set grid search through cross validation\n",
    "grid = GridSearchCV(estimator=NN_pipe, param_grid=param_grid, cv=2, verbose=4, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit model to training data\n",
    "grid.fit(X_trainC, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we print the best combination of hyperparameters found by the grid search and the corresponding score, as well as calculating the root mean squared error (RMSE) of the best estimator. The results of the grid search are also stored in a data frame. Finally, the best model is used to make predictions on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best parameter and score\n",
    "print(\"Best parameter (CV score=%0.3f):\" % grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "# Root mean square prediction error estimate of best estimator\n",
    "from numpy import sqrt\n",
    "rmse_nn = sqrt(-1*grid.best_score_)\n",
    "rmse_nn\n",
    "\n",
    "# Store grid search results in a data frame\n",
    "res_nn = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "# Predictions with best performing model on test set\n",
    "y_pred_bm_nn = grid.predict(X_testC)\n",
    "y_pred_bm_nn = pd.DataFrame(y_pred_bm_nn,columns=[\"LOS_pred\"])\n",
    "\n",
    "# Data frame to submit to kaggle\n",
    "test_predictions_submit = pd.DataFrame({\"icustay_id\": icustay_id.iloc[:,0] , \"LOS\": y_pred_bm_nn.iloc[:,0]})\n",
    "\n",
    "# Convert to CSV\n",
    "test_predictions_submit.to_csv(\"predictionNN.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model interpretability "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is using the Lime library to generate an explanation for a specific prediction made by the neural network model. The explanation consists of a list of tuples, where each tuple contains a feature name, a weight, and a description of the feature's impact on the prediction. The weights represent the relative importance of the features for the prediction, and the descriptions indicate whether the feature increased or decreased the predicted output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LimeExplainer\n",
    "#explainer = LimeTabularExplainer(training_data=X_trainC, feature_names=X_trainC.columns,\n",
    "                                   class_names=['LOS'], kernel_width=3)\n",
    "\n",
    "# Explain the prediction for a specific instance\n",
    "#instance = X_testC[0]\n",
    "#explanation = explainer.explain_instance(data_row=instance, predict_fn=grid.predict)\n",
    "\n",
    "# Print the explanation\n",
    "#print(explanation.as_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.6) STACKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code is creating a stacking regressor, which is an ensemble model that combines the predictions of multiple base models to make a final prediction. The base models are fit to the training data and the final prediction is made by a meta-model, which is trained on the predictions made by the base models.\n",
    "\n",
    "The code is defining three base models: a random forest regressor, an XGBoost regressor, and a neural network.The code is also defining the meta-model as a random forest regressor. The meta-model will be trained on the predictions made by the base models on the training data and used to make final predictions on new data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary classes\n",
    "\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, ShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Preprocess the training data\n",
    "X_trainC_preprocessed = preprocessing.fit_transform(X_trainC,y_train)\n",
    "X_testC_preprocessed = preprocessing.transform(X_testC)\n",
    "\n",
    "# Define the hyperparameters to tune and their possible values for each base model\n",
    "rf_params = {'n_estimators': [10, 50, 100, 200],\n",
    "             'max_depth': [5, 10, 20]}\n",
    "xgb_params = {'n_estimators': [10, 50, 100, 200],\n",
    "              'max_depth': [ 5, 10, 20]}\n",
    "nn_params = {'hidden_layer_sizes': [(10,), (50,), (100,), (200,)],\n",
    "             'activation': ['relu', 'tanh']}\n",
    "\n",
    "# Create the base models\n",
    "base_models = [('RF', GridSearchCV(RandomForestRegressor(), rf_params, cv=5, verbose=4, n_jobs=-1)),\n",
    "               ('XGB', GridSearchCV(XGBRegressor(), xgb_params, cv=5, verbose=4, n_jobs=-1)),\n",
    "               ('NN', GridSearchCV(model, nn_params, cv=5, verbose=4, n_jobs=-1))]\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = RandomForestRegressor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters being tuned are the base models and the meta-model. Once the grid search is complete, the best combination of hyperparameters is printed and the root mean squared error (RMSE) of the best estimator is calculated and stored. Finally, the best model is used to make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hyperparameters to tune and their possible values for the meta-model\n",
    "stack_params = {\n",
    "    'estimators': base_models,\n",
    "    'final_estimator': [meta_model],\n",
    "}\n",
    "\n",
    "# Set grid search through cross validation for the stacking regressor\n",
    "grid_stack = GridSearchCV(StackingRegressor(estimators=base_models), stack_params,\n",
    "                          cv=5, verbose=4, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "grid_stack.fit(X_trainC_preprocessed, y_train)\n",
    "\n",
    "# Print best parameter and score\n",
    "print(\"Best parameter (CV score=%0.3f):\" % grid_stack.best_score_)\n",
    "print(grid_stack.best_params_)\n",
    "\n",
    "# Root mean square prediction error estimate of best estimator\n",
    "rmse_cv_st = -1*grid_stack.best_score_\n",
    "rmse_cv_st\n",
    "\n",
    "# Store grid search results in a data frame\n",
    "res_st = pd.DataFrame(grid_stack.cv_results_)\n",
    "\n",
    "# Predictions with best performing model on test set\n",
    "y_pred_bm_st = grid_stack.predict(X_testC_preprocessed)\n",
    "y_pred_bm_st = pd.DataFrame(y_pred_bm_st, columns=[\"LOS_pred\"])\n",
    "\n",
    "# Data frame to submit to kaggle\n",
    "test_predictions_submit_st = pd.DataFrame({\"icustay_id\": icustay_id.iloc[:, 0],\n",
    "                                           \"LOS\": y_pred_bm_st.iloc[:, 0]})\n",
    "\n",
    "# Convert to CSV\n",
    "test_predictions_submit_st.to_csv(\"predictionST.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
